{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz = np.load('processeddata.npz')\n",
    "xtrain = npz['xtrain']\n",
    "ytrain = npz['ytrain']\n",
    "xtest = npz['xtest']\n",
    "ytest = npz['ytest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4681, 37) (4681,) (3122, 37) (3122,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape, ytrain.shape, xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\conda\\conda\\envs\\py3-TF2.0\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100, class_weight='balanced', max_iter=200)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LogisticRegression(C=100, max_iter=200, class_weight='balanced')\n",
    "reg.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8102969450972014"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, precision_score, confusion_matrix, accuracy_score\n",
    "\n",
    "def eval(ytest, ypred):\n",
    "    print('\\nEvaluation:')\n",
    "    print('accuracy: '+ str(metrics.accuracy_score(ytest, ypred)))\n",
    "    print('recall: ' + str(metrics.recall_score(ytest, ypred)))\n",
    "    print('F1 score: ' + str(metrics.f1_score(ytest, ypred)))\n",
    "    print('precision: ' + str(metrics.precision_score(ytest, ypred)))\n",
    "    print('==================')\n",
    "    print('\\nConfusion Matrix:')\n",
    "    print(' TN,  FP, FN, TP')\n",
    "    print(confusion_matrix(ytest, ypred).ravel())\n",
    "    print('==================')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:\n",
      "accuracy: 0.8142216527866752\n",
      "recall: 0.855143031040779\n",
      "F1 score: 0.8289085545722713\n",
      "precision: 0.8042358328563252\n",
      "==================\n",
      "\n",
      "Confusion Matrix:\n",
      " TN,  FP, FN, TP\n",
      "[1137  342  238 1405]\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "ypred = reg.predict(xtest)\n",
    "eval(ytest, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:\n",
      "accuracy: 0.8074951953875721\n",
      "recall: 0.847839318320146\n",
      "F1 score: 0.8225568349571891\n",
      "precision: 0.7987385321100917\n",
      "==================\n",
      "\n",
      "Confusion Matrix:\n",
      " TN,  FP, FN, TP\n",
      "[1128  351  250 1393]\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(leaf_size=8, metric='manhattan',weights='uniform')\n",
    "knn.fit(xtrain, ytrain)\n",
    "ypredknn = knn.predict(xtest)\n",
    "eval(ytest, ypredknn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:\n",
      "accuracy: 0.9375400384368994\n",
      "recall: 0.9427875836883749\n",
      "F1 score: 0.9407834801093228\n",
      "precision: 0.9387878787878788\n",
      "==================\n",
      "\n",
      "Confusion Matrix:\n",
      " TN,  FP, FN, TP\n",
      "[1378  101   94 1549]\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(criterion='entropy')\n",
    "tree.fit(xtrain, ytrain)\n",
    "ypredtree = tree.predict(xtest)\n",
    "eval(ytest, ypredtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:\n",
      "accuracy: 0.9612427930813581\n",
      "recall: 0.9500912964090079\n",
      "F1 score: 0.9626888683317915\n",
      "precision: 0.975625\n",
      "==================\n",
      "\n",
      "Confusion Matrix:\n",
      " TN,  FP, FN, TP\n",
      "[1440   39   82 1561]\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, criterion='entropy')\n",
    "forest.fit(xtrain, ytrain)\n",
    "ypredforest = forest.predict(xtest)\n",
    "eval(ytest, ypredforest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'n_estimators': [5, 50, 100, 150, 200],\n",
    "    'max_depth': list(range(1, 11)),\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_features': list(range(1,20)),\n",
    "    'oob_score':[False,True],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3800 candidates, totalling 19000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed: 21.9min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed: 29.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed: 39.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed: 49.7min\n",
      "[Parallel(n_jobs=-1)]: Done 11234 tasks      | elapsed: 53.4min\n",
      "[Parallel(n_jobs=-1)]: Done 12784 tasks      | elapsed: 59.0min\n",
      "[Parallel(n_jobs=-1)]: Done 14434 tasks      | elapsed: 68.3min\n",
      "[Parallel(n_jobs=-1)]: Done 16184 tasks      | elapsed: 80.8min\n",
      "[Parallel(n_jobs=-1)]: Done 18034 tasks      | elapsed: 95.4min\n",
      "[Parallel(n_jobs=-1)]: Done 19000 out of 19000 | elapsed: 104.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.9580397181294042\n",
      "Recall: 0.9404176904176904\n",
      "F1 Score: 0.9589727528969622\n",
      "Precision: 0.9782747603833866\n",
      "\n",
      "Confusion Matrix:\n",
      " TN,  FP, FN, TP\n",
      "[1460   34   97 1531]\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(forest, parameters, cv=5, verbose=1, n_jobs=-1)\n",
    "grid.fit(xtrain, ytrain)\n",
    "ypredgrid = grid.predict(xtest)\n",
    "evaluation(ytest, ypredgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-TF2.0",
   "language": "python",
   "name": "py3-tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
